{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#QnA Bot from Youtube Playlist\n",
        "\n",
        "This project enables users to generate transcripts for videos in a YouTube playlist, create embeddings, and ask questions about the video content.\n"
      ],
      "metadata": {
        "id": "Qfczk7QlLbYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Features\n",
        "\n",
        "- Extracts video links from a YouTube playlist.\n",
        "- Generates transcripts for each video.\n",
        "- Creates embeddings for the transcripts.\n",
        "- Provides a Q&A bot to answer questions about the video content."
      ],
      "metadata": {
        "id": "GLiifXUgLm91"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### To run this code follow these steps one by one:\n",
        "\n",
        "### Step 1:\n",
        "Install the necessary dependencies:"
      ],
      "metadata": {
        "id": "SFxXn59TL-bW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install youtube_transcript_api\n",
        "!pip install llama-index-llms-gemini\n",
        "!pip install llama-index-vector-stores-chroma\n",
        "!pip install llama-index-embeddings-huggingface\n",
        "!pip install llama-index-core\n",
        "!pip install google-api-python-client\n",
        "!pip install llama-hub-youtube-transcript\n",
        "!pip install llama-index-readers-youtube-transcript"
      ],
      "metadata": {
        "id": "NsdGIM0gMgQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2:\n",
        "\n",
        "Create a class and module that accepts a YouTube playlist URL and generates a list of individual YouTube video links from that playlist."
      ],
      "metadata": {
        "id": "cvegZQviNPog"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fHfNB6UoJrz_"
      },
      "outputs": [],
      "source": [
        "# Import necessary classes from different modules\n",
        "import googleapiclient.discovery\n",
        "from urllib.parse import parse_qs, urlparse\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "class YouTubePlaylist:\n",
        "    def __init__(self, url):\n",
        "        # Extract the playlist ID from the provided URL\n",
        "        query = parse_qs(urlparse(url).query, keep_blank_values=True)\n",
        "        self.playlist_id = query[\"list\"][0]\n",
        "\n",
        "        # Load the API key from the .env file\n",
        "        load_dotenv()\n",
        "        self.api_key = os.getenv(\"YOUTUBE_API_KEY\")\n",
        "\n",
        "        # Build the YouTube API client using the API key\n",
        "        self.youtube = googleapiclient.discovery.build(\"youtube\", \"v3\", developerKey=self.api_key)\n",
        "\n",
        "    def get_playlist_items(self):\n",
        "        # Create an API request to get playlist items\n",
        "        request = self.youtube.playlistItems().list(\n",
        "            part=\"snippet\",\n",
        "            playlistId=self.playlist_id,\n",
        "            maxResults=50  # Maximum number of results to return per request\n",
        "        )\n",
        "\n",
        "        playlist_items = []\n",
        "        while request is not None:\n",
        "            # Execute the request and get the response\n",
        "            response = request.execute()\n",
        "            # Add the items from the response to the playlist_items list\n",
        "            playlist_items += response[\"items\"]\n",
        "            # Get the next page of results, if available\n",
        "            request = self.youtube.playlistItems().list_next(request, response)\n",
        "\n",
        "        # Extract the video links from the playlist items\n",
        "        links = [\n",
        "            f'https://www.youtube.com/watch?v={t[\"snippet\"][\"resourceId\"][\"videoId\"]}&list={self.playlist_id}'\n",
        "            for t in playlist_items\n",
        "        ]\n",
        "        return links\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3:\n",
        "\n",
        "Create a class that accepts a YouTube video link and returns the transcript of the video."
      ],
      "metadata": {
        "id": "st0AYSudOGvL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary classes from different modules\n",
        "from llama_index.readers.youtube_transcript import YoutubeTranscriptReader\n",
        "\n",
        "class Transcript_Generator:\n",
        "    def __init__(self, url):\n",
        "        # Initialize the Transcript_Generator with a YouTube URL\n",
        "        self.url = url\n",
        "        # Create an instance of YoutubeTranscriptReader to load transcripts\n",
        "        self.loader = YoutubeTranscriptReader()\n",
        "\n",
        "    def generate_Transcript(self):\n",
        "        # Use the loader to fetch transcript data for the given YouTube URL\n",
        "        documents = self.loader.load_data(\n",
        "            ytlinks=[self.url]  # Pass the URL as a list to the load_data method\n",
        "        )\n",
        "        return documents  # Return the loaded transcript documents"
      ],
      "metadata": {
        "id": "_hRA2xOtKZoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4:\n",
        "\n",
        "Create a class that accepts a transcript, generates embeddings from it, and stores these embeddings in a ChromaDB database."
      ],
      "metadata": {
        "id": "l-6M-xa4Oo0O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary classes from different modules\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "import chromadb\n",
        "from llama_index.core import (\n",
        "    Settings, StorageContext, VectorStoreIndex\n",
        ")\n",
        "from llama_index.llms.gemini import Gemini\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
        "\n",
        "class Generator:\n",
        "    def __init__(self, data):\n",
        "        # Load environment variables\n",
        "        load_dotenv()\n",
        "        self.api_key = os.getenv('GEMINI_API_KEY')\n",
        "\n",
        "        # Set embedding and language models\n",
        "        self.embedding_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-base-en-v1.5\")\n",
        "        self.llm = Gemini(api_key=self.api_key, model_name=\"models/gemini-pro\")\n",
        "\n",
        "        # Load documents\n",
        "        self.documents = data\n",
        "\n",
        "        # Create a client and a new collection\n",
        "        self.client = chromadb.PersistentClient(path='./chroma_db')\n",
        "        self.chroma_collection = self.client.get_or_create_collection(\"quickstart\")\n",
        "\n",
        "        # Create a vector store\n",
        "        self.vector_store = ChromaVectorStore(chroma_collection=self.chroma_collection)\n",
        "\n",
        "        # Create a storage context\n",
        "        self.storage_context = StorageContext.from_defaults(vector_store=self.vector_store)\n",
        "\n",
        "        # Set Global settings\n",
        "        Settings.llm = self.llm\n",
        "        Settings.embed_model = self.embedding_model\n",
        "\n",
        "    # Create an index from the documents and save it to the disk\n",
        "    def generate_embeddings(self):\n",
        "        self.index = VectorStoreIndex.from_documents(\n",
        "        self.documents, storage_context=self.storage_context\n",
        "    )"
      ],
      "metadata": {
        "id": "tbkNIUp8Kq39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5:\n",
        "\n",
        "Create a classs to generate answers by querying the index with a given question."
      ],
      "metadata": {
        "id": "uMKlqBbFPIMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary classes from different modules\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "from llama_index.core import Settings, VectorStoreIndex, StorageContext\n",
        "from llama_index.llms.gemini import Gemini\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
        "import chromadb\n",
        "\n",
        "class Retriever:\n",
        "    def __init__(self):\n",
        "        # Load environment variables\n",
        "        load_dotenv()\n",
        "        self.api_key = os.getenv('GEMINI_API_KEY')\n",
        "\n",
        "        if not self.api_key:\n",
        "            raise ValueError(\"API key for Gemini model is not set.\")\n",
        "\n",
        "        # Initialize the Gemini embedding model\n",
        "        self.embedding_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-base-en-v1.5\")\n",
        "\n",
        "        # Initialize the Gemini language model\n",
        "        self.llm = Gemini(api_key=self.api_key, model_name=\"models/gemini-pro\")\n",
        "\n",
        "        # Set Global settings\n",
        "        Settings.llm = self.llm\n",
        "        Settings.embed_model = self.embedding_model\n",
        "\n",
        "        # Load the ChromaDB client\n",
        "        self.client = chromadb.PersistentClient(path='./chroma_db')\n",
        "\n",
        "        # Fetch the collection from ChromaDB\n",
        "        self.chroma_collection = self.client.get_collection(\"quickstart\")\n",
        "\n",
        "        # Fetch the vector store from the collection\n",
        "        self.vector_store = ChromaVectorStore(chroma_collection=self.chroma_collection)\n",
        "\n",
        "        # Create a storage context\n",
        "        self.storage_context = StorageContext.from_defaults(vector_store=self.vector_store)\n",
        "\n",
        "        # Get the index from the vector store\n",
        "        self.index = VectorStoreIndex.from_vector_store(self.vector_store)\n",
        "\n",
        "    def generate_answers(self, question):\n",
        "        query_engine = self.index.as_query_engine()\n",
        "        return query_engine.query(question)"
      ],
      "metadata": {
        "id": "DxD7tiqRLA3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 6:\n",
        "\n",
        "Run each of the classes in the specified order to ensure proper initialization and functionality."
      ],
      "metadata": {
        "id": "OY2i430nPm2C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary classes from different modules\n",
        "from Links_Generator import YouTubePlaylist\n",
        "from Transcript_Generator import Transcript_Generator\n",
        "from generator import Generator\n",
        "from retriever import Retriever\n",
        "\n",
        "# Prompt the user to enter the YouTube playlist URL\n",
        "url = str(input(\"Enter the YouTube playlist URL: \"))\n",
        "\n",
        "# Initialize the YouTubePlaylist object with the provided URL\n",
        "yt_playlist = YouTubePlaylist(url)\n",
        "\n",
        "# Get the list of video links from the playlist\n",
        "links = yt_playlist.get_playlist_items()\n",
        "\n",
        "# Initialize a counter for video numbering\n",
        "i = 1\n",
        "\n",
        "# Loop through each video link in the playlist\n",
        "for link in links:\n",
        "    # Initialize the Transcript_Generator object with the video link\n",
        "    init_transcript = Transcript_Generator(link)\n",
        "\n",
        "    # Generate the transcript for the current video\n",
        "    transcript = init_transcript.generate_Transcript()\n",
        "\n",
        "    # Prepare the input string for the current video with its transcript\n",
        "    inp = f\"Video {i}:\\n {transcript}\"\n",
        "\n",
        "    # Print the input string (video number and its transcript)\n",
        "    print(inp)\n",
        "\n",
        "    # Initialize the Generator object with the transcript\n",
        "    generator = Generator(transcript)\n",
        "\n",
        "    # Generate embeddings for the transcript\n",
        "    embeddings = generator.generate_embeddings()\n",
        "\n",
        "    # Increment the video counter\n",
        "    i += 1\n",
        "\n",
        "# Initialize the Retriever object\n",
        "init_retriever = Retriever()\n",
        "\n",
        "# Continuously prompt the user for questions until they type 'exit'\n",
        "while True:\n",
        "    # Prompt the user to ask a question\n",
        "    question = str(input(\"Ask any question (type 'exit' to quit): \"))\n",
        "\n",
        "    # Check if the user wants to exit\n",
        "    if question.lower() == \"exit\":\n",
        "        break\n",
        "\n",
        "    # Generate an answer for the user's question\n",
        "    answer = init_retriever.generate_answers(question)\n",
        "\n",
        "    # Print the answer\n",
        "    print(answer)"
      ],
      "metadata": {
        "id": "9-a2LcqSLI1P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
